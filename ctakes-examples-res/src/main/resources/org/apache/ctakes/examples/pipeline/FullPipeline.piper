
// Advanced Tokenization: Regex sectionization, BIO Sentence Detector (lumper), Paragraphs, Lists
load FullTokenizerPipeline
// OR use the standard tokenizer pipeline:
//load DefaultTokenizerPipeline

// Always need these ...
add ContextDependentTokenizerAnnotator
add POSTagger

// Chunkers
load ChunkerSubPipe

// Default fast dictionary lookup
set minimumSpan=2
load DictionarySubPipe

// Cleartk Entity Attributes (negation, uncertainty, etc.)
load AttributeCleartkSubPipe

// Entity Relations (degree/severity, anatomical location)
load RelationSubPipe

// Temporal (event, time, dtr, tlink)
load TemporalSubPipe

// Coreferences (e.g. patient = he)
load CorefSubPipe

// Html output
add pretty.html.HtmlTextWriter

// XMI output
//writeXmis
